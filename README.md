# Chess Tactic Classification & Provision of Conceptual Reasoning Via Machine Learning
### Background

Chess and technology have become intertwined since IBM's Deep Blue beat the best player in the world, Garry Kasparov, in 1977. Since then, chess AI’s have permanently altered how the game is played. By evaluating hundreds of thousands of possibilities, chess AI’s have enabled everyone from a novice to a grandmaster to view the game at a very analytical level. However, they struggle with giving explanations to why a move is good or bad. With the resurgence of chess into popular culture, understanding modern engines (such as Stockfish) has become a barrier to entry for chess.

### Problem Definition

Online chess players use chess engines on sites like chess.com or Lichess to review their games everyday, but they are not given information on why certain moves are good or bad. For students of chess, the puzzles on these sites can present opportunities for these more conceptual ideas to be presented and learned. However, during game analysis, engines like Stockfish simply evaluate moves on a numerical scale which lacks the conceptual feedback a user can directly apply to improve their skills. <br><br>
We imagine a program that can analyze moves and give helpful constructive feedback to intermediate chess players. If a user makes a bad move that could get a piece stuck, it would output something like “bad move: allows knight to be pinned on b5.” Data from puzzles, matches, and results can be evaluated to help us classify why the next move given by Stockfish is a good move.


Here's a more in depth example:
![chess1](https://user-images.githubusercontent.com/32807310/136492810-1b30453b-7ecd-45b8-b948-095ea8937114.JPG)<br>
In the above puzzle, stockfish recommends that Qxc3 in what appears to be a very basic trade after white responds with Rxc3:<br>
![chess2](https://user-images.githubusercontent.com/32807310/136488962-ba4af350-45b1-4261-9cac-669797859343.JPG)<br>
The tactic behind this queen trade is the followup move of Bxd4, which forks the rook on c3 and white’s king on g1:<br>
![chess3](https://user-images.githubusercontent.com/32807310/136489031-06ebc1b1-ffca-4c8f-ba52-969c1590045d.JPG)<br>

Through this three stage sequence, Stockfish has recommended all of the best possible moves, assigning them a rating corresponding to the advantage one player has over the other. In the last screenshot, Stockfish is evaluating black to have an advantage equivalent to 4.9 pawns over white, putting them in the lead. However, Stockfish fails to provide the player with any explanation/classification through these moves as to why this sequence is advantageous, which deprives the player of understanding. Our AI would recognize that Qxc3 leads to a fork and inform the player, allowing the player to quickly understand why a move is powerful without requiring prior knowledge of forking.
<br><br>

### Data Collection
  Our raw data was sourced from https://database.lichess.org/#puzzles, which contains a csv hosting all of the puzzles hosted and collected on lichess.com. This looked like the following:<br>
  ![Original CSV](https://user-images.githubusercontent.com/32807310/142178936-c3ba898c-36b3-4355-8b48-7ce46614348d.png)<br>
  Each entry in the CSV contained both the initial board state in FEN notation (column 2), the moves necessary to finish the puzzle (column 3) and “theme” tags (column 8) categorizing which type of puzzle each instance was. We then cleaned the data, which happened in a few steps. <br><br>
  The first step eliminated all puzzles which did not correspond to a theme of interest. In particular, we considered themes which were of both high numerical count and of low ambiguity. For example, themes like “crushing” or “bishop endgame” were cases that we believed to be too ambiguous for our model to be able to properly define, at least based on the amount of data available. After whittling down this list of puzzle themes, we were left with 6 easily definable and trainable themes: “hanging piece”, “fork”, “trappedPiece”, “pin”, “backrank mate”, and “skewer”.<br><br>
  After doing this, we deleted the columns containing information irrelevant to our use case. Information such as puzzle ELO rating, lichess link, and lichess label were deleted until we were left with only the starting chess puzzle position, moves necessary to complete the puzzle, and cleaned themes.<br><br>
  One last thing to keep in mind is that our dataset contained puzzles that were easy to hard in complexity. The easy puzzles can be solved in just two moves, while the hard ones might take over 8 steps. Since some puzzles in our dataset had varying numbers of moves to solve, we organized the data for the different number of moves that are required to solve a puzzle. We have datasets for the puzzles that take 2, 4, 6, 8, and 10 steps to solve in different files. We used these files as different datasets in our algorithm and trained individual models corresponding to each.

### Methods

We used supervised learning in order to accomplish this task by using the puzzle data sets from lichess.com. Using the cleaned data, we were able to utilize the libraries of Tensorflow, pandas, numpy, and python-chess to create our model. Python-chess was the library that we used to take the standard chess notation from our data and organize it into something that Tensorflow, our library used for machine learning algorithms, could better understand. This meant that we did not need to manually change the string notations into numbers for our very large dataset, and instead, we simply utilized a library to do it for us. To begin our model, we first needed to organize the cleaned data into matrices that could be readable to a supervised learning algorithm. We used methods common to other machine learning analysis of chess data and split our information into many 12 8x8 matrices per board position to create a large multidimensional array which contained the position of each piece on the board. In more complex detail, these 8x8 arrays were one hot encoded to each of black and white’s chess pieces. For example, the first 8x8 array was one hot encoded to display the location of white’s pawns, the next array white’s knights, etc. and, starting at the 7th array, the process was repeated for black.<br><br>
Likewise, In order to better obtain our results, we needed to change the way that we thought about our labels. This is because in some other machine learning problems labels can be used to wholly represent a specific piece of data, but in our case, we are dealing with the possibilities of multiple classifications per piece of data. The issue with the ordinary approach of giving one data point one label is that a specific data can actually belong to multiple labels. We have labels like fork, pin, and skewer. This is all chess jargon for different scenarios that can occur with the pieces, but multiple scenarios can occur at once. It is possible to both pin and fork your opponent at the same time. To accommodate for this, we used the one-hot technique. We used an array of the same size as the number of our labels, and placed a 1 in the corresponding column if the data point was assigned that label. So if we had 6 labels and a certain point was assigned fork and pin, then the one-hot representation of this would be [0, 1, 0, 1, 0, 0] if the 1st and 3rd index indicated fork and pin.<br><br>
We utilized the technique of splitting the dataset into training and testing. We decided on having 80% of our data used for training, and the other 20% used for testing. We are aware of the fact that many other models may have higher proportions of their dataset used for training, like 90%, but we thought that 80% would be a good number given the large size of the dataset that we have and a method to mitigate overfitting.<br><br>
Tensorflow’s Keras neural network implementation was deemed to be the most fitting supervised learning technique we could implement. This was largely because of its modularity, wealth of online documentation, ease of use, and ability to handle multi classification scenarios such as our own. While we are still experimenting with the perfect allotment of layers in our model and will likely fine-tune the model for the final presentation, it’s current state is adequate. The model takes advantage of the tf.keras.Sequential() library, which makes sense for our use case as we are inputting one large tensor corresponding to the shape/dimensions of #puzzles x #number of moves x (12 x 8 x 8 ), which was the board representation previously discussed. To help the model process this information, there is a flatten layer which transforms the data into a more parsable format. Following this layer, there are two intermediary dense layers with 128 and 64 nodes respectively, both with activation function “relu”, which we discovered to be the best for our use case after some research and reference of previous projects. Finally, we have an output layer of 6 nodes, corresponding to our 6 puzzle theme types with an activation function of softmax to account for multi classification possibilities.<br><br>
For assessing our model, we chose to use the adam optimizer, a loss function of categorical_crossentropy, output metric of accuracy, and an epoch count of 10. Based on our research, both the adam optimizer and categorical_crossentropy have seen wide use in one hot and multi classification examples, so we followed in those footsteps, but will perhaps experiment in the future. Of course, accuracy was also output to define an easily conceptualized metric that evaluated the overall success of our algorithm. Finally, we chose to use the relatively low epoch count of 10 as we are still fine tuning our model and for time’s sake wished to keep training short and additionally saw only a negligible difference in accuracy over time past 10 epochs. 

### Results

Recall that we split our data into the different number of moves that are required to solve the puzzles. We ran our algorithm for 6 of these datasets: 2, 4, 6, 8, and 10. Because of the way we captured our data, we simply needed to change the parameter in our call to designModel() in order to reference another dataset and run the model. Below, we have the results of the algorithm for the puzzles that required two moves to solve.<br>
![CMD Output](https://user-images.githubusercontent.com/32807310/142179880-e095e2fb-171a-4b44-9312-9ddb3fc3518d.png)<br>
Here is the same information in a more visual format.<br>
![2 Move Chart](https://user-images.githubusercontent.com/32807310/142180713-b52151f2-8119-40a7-98e1-3bbdc35ebbe6.JPG)<br>
![2 Move Loss](https://user-images.githubusercontent.com/32807310/142180850-aa56c643-c3bf-4c31-b804-d9baae8d67ab.png)<br>
![2 Move Accuracy](https://user-images.githubusercontent.com/32807310/142180873-f34e1818-dff5-498b-804f-b1fa6ae4ab73.png)<br>
Testing accuracy: .708 Test Loss: 1981.205<br><br>
Model for puzzles with 4 moves:<br>
![4 Move Loss](https://user-images.githubusercontent.com/32807310/142181186-60784e58-9e7d-43fd-848a-a6cd5aeafd85.png)<br>
![4 Move Accuracy](https://user-images.githubusercontent.com/32807310/142181191-376b7df0-e0b2-4643-8270-a40b9d4994a0.png)<br>
Testing accuracy: .479 Test Loss: 240209.563 <br><br>
Model for puzzles with 6 moves:<br>
![6 Move Loss](https://user-images.githubusercontent.com/32807310/142181505-6541a138-6048-41dd-a297-5932485a19a1.png)<br>
![6 Move Accuracy](https://user-images.githubusercontent.com/32807310/142181512-aa3baef6-aa83-40f0-a8c6-3d9a2e02c4ff.png)<br>
Testing accuracy: .490 Test Loss: 77623.359<br><br>
![8 Move Loss](https://user-images.githubusercontent.com/32807310/142181895-a624b951-4a70-4b93-81eb-92d09c7dc6e3.png)<br>
![8 Move Accuracy](https://user-images.githubusercontent.com/32807310/142181900-a950a955-edf8-4488-bc74-f7ddb8a348eb.png)<br>
Testing accuracy: .530 Test Loss: 7406.889<br><br>
![10 Move Loss](https://user-images.githubusercontent.com/32807310/142182069-f888d891-0064-45bd-bbe4-e8e32971275c.png)<br>
![10 Move Accuracy](https://user-images.githubusercontent.com/32807310/142182121-6a0d9cc2-0d45-4521-87e5-dd41b5dbe859.png)<br>
Testing accuracy: .512 Test Loss: 1023.130

### Discussion

In terms of numerical relationships, models which had a higher volume of input data expectedly corresponded to high loss values; model 4, which had the most training data (~440,000) had the most loss (240209.563) whereas model 10, which had the least training data (~7,800) had the least loss (1023.130). Model accuracy was more complexity correlated, seemingly depending on a combination of the amount of training data and the number of puzzles/moves/input features. The .703 accuracy of model 2 and it’s relative success by comparison to the rest of the models will certainly be studied and hopefully replicated in preparation for the final presentation. Likewise, the consistent exponential relationship between loss and epochs will be studied and potentially corrected with the application of higher epoch counts, layer manipulation, experimentation with learning rate, and further research of gradient descent and loss as a whole.<br><br>

One thing to take away from the results is that although the accuracy is much higher than a guess, the model still makes many mistakes. This means that if this were to eventually be displayed as a tool for the online chess community the accuracy needs to be higher. Therefore, this has led us to look for ways to improve the results. One potential solution is to find more data since splitting our original data into different numbers of moves substantially lowered the amount of training data. Therefore, we can look into getting more puzzle data from other websites which would allow for higher training counts but we run the risk of having to clean out duplicate, reused puzzles.<br><br>

Another consideration we might have is changing the classification/learning algorithm. Currently we are using a NN to accomplish the goal, however, since puzzles and the game of chess depend highly on the previous states of the board, we could potentially change the algorithm to a Bayes Net using the states of the board and the probability of making each individual move as the parameters. However, this method would take a substantial amount of work in choosing how to calculate the probabilities of each move and would be a difficult task.<br><br>

Lastly, another consideration is that our team was modifying the parameters of the network. Currently, we have not experimented with many different combinations of hidden layers. Changing these layers could have a significant change into the performance of the network as too many can cause overfitting or large training times. Another way we could change the network is by modifying the activation functions. Currently we are using one of the standard functions that comes inside of tensorflow, but we could potentially look into using a custom activation function that can better suit the input of our network.<br><br>

Overall, the project is trending towards a positive direction and, with some more fine tuning, this set of models could become a practical tool chess players use to analyze and conceptualize their games. <br><br>

### References

Masud M., Al-Shehhi A., Al-Shamsi E., Al-Hassani S., Al-Hamoudi A., Khan L. (2015) Online Prediction of Chess Match Result. In: Cao T., Lim EP., Zhou ZH., Ho TB., Cheung D., Motoda H. (eds) Advances in Knowledge Discovery and Data Mining. PAKDD 2015. Lecture Notes in Computer Science, vol 9077. Springer, Cham. https://doi.org/10.1007/978-3-319-18038-0_41

Reid McIlroy-Young, Siddhartha Sen, Jon Kleinberg, and Ashton Anderson. 2020. Aligning Superhuman AI with Human Behavior: Chess as a Model System. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD '20). Association for Computing Machinery, New York, NY, USA, 1677–1687. DOI:https://doi.org/10.1145/3394486.3403219

Reiser P.G.K., Riddle P.J. (1999) Evolving Logic Programs to Classify Chess-Endgame Positions. In: McKay B., Yao X., Newton C.S., Kim JH., Furuhashi T. (eds) Simulated Evolution and Learning. SEAL 1998. Lecture Notes in Computer Science, vol 1585. Springer, Berlin, Heidelberg. https://doi.org/10.1007/3-540-48873-1_19
